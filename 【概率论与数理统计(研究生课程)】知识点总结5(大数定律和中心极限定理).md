# 【概率论与数理统计(研究生课程)】知识点总结5(大数定律和中心极限定理)

## 伯努利大数定律

$$
\lim_{n\rightarrow\infty}P\{|\frac{n_A}{n}-p|<\epsilon\}=1
$$

## 大数定律

$$
\begin{aligned}
\lim_{n\rightarrow\infty}P\{|\frac{1}{n}\sum\limits_{k=1}^{\infty}X_k-a_n|\ge\epsilon \}=0 \\
\lim_{n\rightarrow\infty}P\{|\frac{1}{n}\sum\limits_{k=1}^{\infty}X_k-a_n|<\epsilon \}=1
\end{aligned}
$$

## 切比雪夫大数定律

条件：期望、方差存在且相同
$$
\begin{aligned}
\lim_{n\rightarrow\infty}P\{|\frac{1}{n}\sum\limits_{k=1}^{\infty}X_k-\mu|<\epsilon \}=1 \\
\lim_{n\rightarrow\infty}P\{|\frac{1}{n}\sum\limits_{k=1}^{\infty}X_k-\frac{1}{n}\sum\limits_{k=1}^{\infty}E(X_k)|<\epsilon \}=1 
\end{aligned}
$$

## 辛钦大数定律

条件：独立同分布，期望存在且相同
$$
\lim_{n\rightarrow\infty}P\{|\frac{1}{n}\sum\limits_{k=1}^{\infty}X_k-\mu|<\epsilon \}=1
$$
以上定理表明，当$n$充分大时，随机变量的算数平均值$\frac{1}{n}\sum\limits_{i=1}^{n}X_i$的取值几乎等于期望$\mu$，这就是大数定律的含义。

|     大数定律     |   独立性   | 期望 |   方差   |   用途   |
| :--------------: | :--------: | :--: | :------: | :------: |
|  伯努利大数定律  |  二项分布  | 相同 |   相同   | 估算概率 |
|   辛钦大数定律   | 独立同分布 | 相同 |   相同   | 估算期望 |
| 切比雪夫大数定律 |    独立    | 存在 | 存在有限 | 估算期望 |

## 中心极限定理

中心极限定理讨论：
$$
\frac{\sum\limits_{i=1}^{n}X_i-E(\sum\limits_{i=1}^{n}X_i)}{\sqrt{D(\sum\limits_{i=1}^{n}X_i)}}
$$
对应的分布函数序列收敛于正态分布。
$$
\begin{aligned}
&\lim_{n\rightarrow\infty}P\{\frac{\sum\limits_{i=1}^{n}X_i-E(\sum\limits_{i=1}^{n}X_i)}{\sqrt{D(\sum\limits_{i=1}^{n}X_i)}}\le x\}=\int_{-\infty}^x \frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}}dt=\Phi(x) \\
&Y_n= \frac{\sum\limits_{i=1}^{n}X_i-E(\sum\limits_{i=1}^{n}X_i)}{\sqrt{D(\sum\limits_{i=1}^{n}X_i)}}=\frac{\sum\limits_{i=1}^{n}X_i-n\mu}{\sqrt{n}\sigma}\sim N(0,1) \\
&\sum\limits_{i=1}^{n}X_i=\sqrt{n}\sigma Y_n+n\mu \sim N(n\mu, n\sigma^2)
\end{aligned}
$$
对任意$a\le b$：
$$
P\{a\le\sum\limits_{i=1}^{n}X_i\le b \}=P\{\frac{a-n\mu}{\sqrt{n}\sigma}\le \frac{\sum\limits_{i=1}^{n}X_i-n\mu}{\sqrt{n}\sigma}\le\frac{b-n\mu}{\sqrt{n}\sigma}\}\approx\Phi(\frac{b-n\mu}{\sqrt{n}\sigma})-\Phi(\frac{a-n\mu}{\sqrt{n}\sigma})
$$

## 德莫佛—拉普拉斯定理

$\eta_n\sim B(n,p)$
$$
\lim_{n\rightarrow \infty}P\{\frac{\eta_n-np}{\sqrt{np(1-p)}}\le x \}
=\int\limits_{-\infty}^x\frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}dt}=\Phi(x)
$$
即：二项分布的极限分布是正态分布。

对任意$a\le b$：
$$
P\{a\le\mu_n\le b \}=P\{\frac{a-np}{\sqrt{npq}}\le \frac{\mu_n-np}{\sqrt{npq}}\le\frac{b-np}{\sqrt{npq}}\}\approx\Phi(\frac{b-np}{\sqrt{npq}})-\Phi(\frac{a-np}{\sqrt{npq}})
$$

## 格列文科定理

$$
P\{\lim_{n\rightarrow\infty}\sup_{-\infty< x<+\infty} |F_n(x)-F(x)|=0\}=1
$$

上述定理表明，样本容量$n$足够大时，对所有$x$，$F_n(x)$与$F(x)$之差的绝对值都很小，这件事概率为1，这是==用样本推断整体的依据==。